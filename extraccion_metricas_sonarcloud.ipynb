{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59e116e1",
   "metadata": {},
   "source": [
    "# Extracci√≥n de M√©tricas de Calidad de Software desde SonarCloud\n",
    "\n",
    "Este notebook est√° dise√±ado para cargar datos de estudiantes con proyectos de SonarCloud y extraer m√©tricas de calidad de software utilizando la API de SonarCloud.\n",
    "\n",
    "## Objetivos:\n",
    "1. **Cargar datos** de estudiantes desde el archivo CSV con columnas Sonar_Ap1 y Sonar_Ap2\n",
    "2. **Extraer m√©tricas** de calidad desde SonarCloud API para cada proyecto\n",
    "3. **Procesar y combinar** los datos para crear un dataset completo\n",
    "4. **Exportar resultados** para an√°lisis posteriores\n",
    "\n",
    "## M√©tricas a Extraer:\n",
    "- `bugs`: Errores detectados\n",
    "- `vulnerabilities`: Vulnerabilidades de seguridad\n",
    "- `code_smells`: Problemas de mantenibilidad\n",
    "- `technical_debt`: Deuda t√©cnica\n",
    "- `duplicated_lines_density`: Densidad de l√≠neas duplicadas\n",
    "- `ncloc`: N√∫mero de l√≠neas de c√≥digo\n",
    "- `complexity`: Complejidad ciclom√°tica\n",
    "- `reliability_rating`: Rating de confiabilidad\n",
    "- `sqale_rating`: Rating de mantenibilidad (SQALE)\n",
    "- `open_issues`: Problemas abiertos\n",
    "- `coverage`: Cobertura de c√≥digo\n",
    "- `security_rating`: Rating de seguridad\n",
    "- `security_hotspots`: Puntos cr√≠ticos de seguridad\n",
    "- `comment_lines_density`: Densidad de l√≠neas de comentarios\n",
    "- `cognitive_complexity`: Complejidad cognitiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a98900f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Verificando e instalando dependencias...\n",
      "‚úÖ pandas ya est√° instalado\n",
      "‚úÖ requests ya est√° instalado\n",
      "‚úÖ Todas las dependencias est√°n listas\n"
     ]
    }
   ],
   "source": [
    "# Instalaci√≥n de dependencias (ejecutar solo si es necesario)\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Instalar paquete si no est√° disponible\"\"\"\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"‚úÖ {package} ya est√° instalado\")\n",
    "    except ImportError:\n",
    "        print(f\"üîÑ Instalando {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"‚úÖ {package} instalado exitosamente\")\n",
    "\n",
    "# Lista de paquetes requeridos\n",
    "required_packages = ['pandas', 'requests']\n",
    "\n",
    "print(\"üîß Verificando e instalando dependencias...\")\n",
    "for package in required_packages:\n",
    "    install_package(package)\n",
    "\n",
    "print(\"‚úÖ Todas las dependencias est√°n listas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "013e9528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Librer√≠as importadas correctamente\n",
      "üìù Pandas version: 2.3.1\n",
      "üåê Requests disponible para API calls\n"
     ]
    }
   ],
   "source": [
    "# Importar librer√≠as necesarias\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import base64\n",
    "import time\n",
    "from typing import Dict, List, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente\")\n",
    "print(\"üìù Pandas version:\", pd.__version__)\n",
    "print(\"üåê Requests disponible para API calls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca68f0e",
   "metadata": {},
   "source": [
    "## 1. Configuraci√≥n del Entorno\n",
    "\n",
    "En esta secci√≥n importamos todas las librer√≠as necesarias para el procesamiento de datos y la comunicaci√≥n con la API de SonarCloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55169ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîê Configuraci√≥n de autenticaci√≥n preparada\n",
      "üìä 15 m√©tricas configuradas para extracci√≥n\n",
      "‚úÖ Headers de API configurados\n"
     ]
    }
   ],
   "source": [
    "# Configuraci√≥n de SonarCloud API\n",
    "SONAR_TOKEN = \"sqa_f5eb0e4e9b4a89c8f4e8b97f096cbc3b5dae5b09\"\n",
    "SONAR_BASE_URL = \"https://sonarcloud.io/api\"\n",
    "\n",
    "# Configurar headers para autenticaci√≥n\n",
    "def get_auth_headers():\n",
    "    \"\"\"Crear headers de autenticaci√≥n para SonarCloud API\"\"\"\n",
    "    # Codificar token en base64 para autenticaci√≥n b√°sica\n",
    "    auth_string = f\"{SONAR_TOKEN}:\"\n",
    "    auth_bytes = auth_string.encode('ascii')\n",
    "    auth_b64 = base64.b64encode(auth_bytes).decode('ascii')\n",
    "    \n",
    "    return {\n",
    "        'Authorization': f'Basic {auth_b64}',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "# Definir m√©tricas a extraer\n",
    "METRICS = [\n",
    "    \"bugs\",                    # Errores detectados\n",
    "    \"vulnerabilities\",         # Vulnerabilidades de seguridad  \n",
    "    \"code_smells\",            # Problemas de mantenibilidad\n",
    "    \"technical_debt\",         # Deuda t√©cnica\n",
    "    \"duplicated_lines_density\", # Densidad de l√≠neas duplicadas\n",
    "    \"ncloc\",                  # N√∫mero de l√≠neas de c√≥digo\n",
    "    \"complexity\",             # Complejidad ciclom√°tica\n",
    "    \"reliability_rating\",     # Rating de confiabilidad\n",
    "    \"sqale_rating\",          # Rating de mantenibilidad (SQALE)\n",
    "    \"open_issues\",           # Problemas abiertos\n",
    "    \"coverage\",              # Cobertura de c√≥digo\n",
    "    \"security_rating\",       # Rating de seguridad\n",
    "    \"security_hotspots\",     # Puntos cr√≠ticos de seguridad\n",
    "    \"comment_lines_density\", # Densidad de l√≠neas de comentarios\n",
    "    \"cognitive_complexity\"   # Complejidad cognitiva\n",
    "]\n",
    "\n",
    "print(\"üîê Configuraci√≥n de autenticaci√≥n preparada\")\n",
    "print(f\"üìä {len(METRICS)} m√©tricas configuradas para extracci√≥n\")\n",
    "print(\"‚úÖ Headers de API configurados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625aab92",
   "metadata": {},
   "source": [
    "## 2. Configuraci√≥n de la API de SonarCloud\n",
    "\n",
    "Configuramos los par√°metros necesarios para conectarnos a SonarCloud:\n",
    "\n",
    "- **Token de autenticaci√≥n**: Credenciales para acceder a la API\n",
    "- **Headers de autenticaci√≥n**: Configuraci√≥n b√°sica con base64 encoding\n",
    "- **M√©tricas objetivo**: Lista de 15 m√©tricas de calidad de software a extraer\n",
    "\n",
    "### M√©tricas de Calidad Configuradas:\n",
    "Las m√©tricas se dividen en varias categor√≠as:\n",
    "- **Errores y vulnerabilidades**: `bugs`, `vulnerabilities`, `security_hotspots`\n",
    "- **Mantenibilidad**: `code_smells`, `technical_debt`, `sqale_rating`\n",
    "- **Complejidad**: `complexity`, `cognitive_complexity`\n",
    "- **Cobertura y documentaci√≥n**: `coverage`, `comment_lines_density`\n",
    "- **Duplicaci√≥n**: `duplicated_lines_density`\n",
    "- **Tama√±o**: `ncloc` (lines of code)\n",
    "- **Ratings**: `reliability_rating`, `security_rating`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "467e4187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Datos cargados exitosamente\n",
      "üë• N√∫mero de estudiantes: 60\n",
      "üìä Columnas disponibles: ['Id', 'Semestre', 'Estudiante', 'Sexo', 'Email', 'Original_Repo_Ap1', 'Original_Repo_Ap2', 'Sonar_Ap1', 'Sonar_Ap2', 'Sonar_Repo_Ap1', 'Sonar_Repo_Ap2']\n",
      "\n",
      "üîç Primeras 3 filas del dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Semestre</th>\n",
       "      <th>Estudiante</th>\n",
       "      <th>Sexo</th>\n",
       "      <th>Email</th>\n",
       "      <th>Original_Repo_Ap1</th>\n",
       "      <th>Original_Repo_Ap2</th>\n",
       "      <th>Sonar_Ap1</th>\n",
       "      <th>Sonar_Ap2</th>\n",
       "      <th>Sonar_Repo_Ap1</th>\n",
       "      <th>Sonar_Repo_Ap2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01</td>\n",
       "      <td>Aaron Eliezer Hern√°ndez Garc√≠a</td>\n",
       "      <td>1</td>\n",
       "      <td>atminifg655@gmail.com</td>\n",
       "      <td>https://github.com/aaron-developer25/SwiftPay.git</td>\n",
       "      <td>https://github.com/aaron-developer25/DealerPOS...</td>\n",
       "      <td>TesisEnel_SwiftPay-Aaron-Ap1</td>\n",
       "      <td>TesisEnel_DealerPOS-Aaron-ap2</td>\n",
       "      <td>https://github.com/TesisEnel/SwiftPay-Aaron-Ap1</td>\n",
       "      <td>https://github.com/TesisEnel/DealerPOS-Aaron-ap2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-03</td>\n",
       "      <td>Abraham El Hage Jreij</td>\n",
       "      <td>1</td>\n",
       "      <td>abrahamelhage2003@gmail.com</td>\n",
       "      <td>https://github.com/JPichardo2003/AguaMariaSolu...</td>\n",
       "      <td>https://github.com/A-EHJ/Final_Project_Ap2.git</td>\n",
       "      <td>TesisEnel_AguaMariaSolution-JulioPichardo-ap1</td>\n",
       "      <td>TesisEnel_Final_Project-Abraham-ap2</td>\n",
       "      <td>https://github.com/TesisEnel/AguaMariaSolution...</td>\n",
       "      <td>https://github.com/TesisEnel/Final_Project-Abr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2024-02</td>\n",
       "      <td>Adiel Luis Garc√≠a Rosa</td>\n",
       "      <td>1</td>\n",
       "      <td>adiel.garcia0422@gmail.com</td>\n",
       "      <td>https://github.com/SamyJp23/PeakPerformance.git</td>\n",
       "      <td>https://github.com/Adiel040/GymProApp.git</td>\n",
       "      <td>TesisEnel_PeakPerformance-samuelAntonio-ap1</td>\n",
       "      <td>TesisEnel_GymProApp-AdielGarcia-Ap2</td>\n",
       "      <td>https://github.com/TesisEnel/PeakPerformance-s...</td>\n",
       "      <td>https://github.com/TesisEnel/GymProApp-AdielGa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id Semestre                      Estudiante  Sexo  \\\n",
       "0   1  2024-01  Aaron Eliezer Hern√°ndez Garc√≠a     1   \n",
       "1   2  2023-03           Abraham El Hage Jreij     1   \n",
       "2   3  2024-02          Adiel Luis Garc√≠a Rosa     1   \n",
       "\n",
       "                         Email  \\\n",
       "0        atminifg655@gmail.com   \n",
       "1  abrahamelhage2003@gmail.com   \n",
       "2   adiel.garcia0422@gmail.com   \n",
       "\n",
       "                                   Original_Repo_Ap1  \\\n",
       "0  https://github.com/aaron-developer25/SwiftPay.git   \n",
       "1  https://github.com/JPichardo2003/AguaMariaSolu...   \n",
       "2    https://github.com/SamyJp23/PeakPerformance.git   \n",
       "\n",
       "                                   Original_Repo_Ap2  \\\n",
       "0  https://github.com/aaron-developer25/DealerPOS...   \n",
       "1     https://github.com/A-EHJ/Final_Project_Ap2.git   \n",
       "2          https://github.com/Adiel040/GymProApp.git   \n",
       "\n",
       "                                       Sonar_Ap1  \\\n",
       "0                   TesisEnel_SwiftPay-Aaron-Ap1   \n",
       "1  TesisEnel_AguaMariaSolution-JulioPichardo-ap1   \n",
       "2    TesisEnel_PeakPerformance-samuelAntonio-ap1   \n",
       "\n",
       "                             Sonar_Ap2  \\\n",
       "0        TesisEnel_DealerPOS-Aaron-ap2   \n",
       "1  TesisEnel_Final_Project-Abraham-ap2   \n",
       "2  TesisEnel_GymProApp-AdielGarcia-Ap2   \n",
       "\n",
       "                                      Sonar_Repo_Ap1  \\\n",
       "0    https://github.com/TesisEnel/SwiftPay-Aaron-Ap1   \n",
       "1  https://github.com/TesisEnel/AguaMariaSolution...   \n",
       "2  https://github.com/TesisEnel/PeakPerformance-s...   \n",
       "\n",
       "                                      Sonar_Repo_Ap2  \n",
       "0   https://github.com/TesisEnel/DealerPOS-Aaron-ap2  \n",
       "1  https://github.com/TesisEnel/Final_Project-Abr...  \n",
       "2  https://github.com/TesisEnel/GymProApp-AdielGa...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Columnas de SonarCloud encontradas: ['Sonar_Ap1', 'Sonar_Ap2', 'Sonar_Repo_Ap1', 'Sonar_Repo_Ap2']\n",
      "üìà Proyectos Sonar_Ap1 disponibles: 60\n",
      "üìà Proyectos Sonar_Ap2 disponibles: 60\n",
      "üìà Total de proyectos a procesar: 120\n"
     ]
    }
   ],
   "source": [
    "# Cargar datos de estudiantes\n",
    "CSV_PATH = \"Estudiantes_2023-2024.csv\"\n",
    "\n",
    "try:\n",
    "    # Cargar el CSV con informaci√≥n de estudiantes\n",
    "    df_estudiantes = pd.read_csv(CSV_PATH)\n",
    "    \n",
    "    print(\"üìÅ Datos cargados exitosamente\")\n",
    "    print(f\"üë• N√∫mero de estudiantes: {len(df_estudiantes)}\")\n",
    "    print(f\"üìä Columnas disponibles: {list(df_estudiantes.columns)}\")\n",
    "    \n",
    "    # Mostrar informaci√≥n b√°sica del dataset\n",
    "    print(\"\\nüîç Primeras 3 filas del dataset:\")\n",
    "    display(df_estudiantes.head(3))\n",
    "    \n",
    "    # Verificar columnas de SonarCloud\n",
    "    sonar_columns = [col for col in df_estudiantes.columns if 'Sonar' in col]\n",
    "    print(f\"\\nüéØ Columnas de SonarCloud encontradas: {sonar_columns}\")\n",
    "    \n",
    "    # Contar proyectos no vac√≠os\n",
    "    sonar_ap1_count = df_estudiantes['Sonar_Ap1'].notna().sum()\n",
    "    sonar_ap2_count = df_estudiantes['Sonar_Ap2'].notna().sum()\n",
    "    \n",
    "    print(f\"üìà Proyectos Sonar_Ap1 disponibles: {sonar_ap1_count}\")\n",
    "    print(f\"üìà Proyectos Sonar_Ap2 disponibles: {sonar_ap2_count}\")\n",
    "    print(f\"üìà Total de proyectos a procesar: {sonar_ap1_count + sonar_ap2_count}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Error: No se encontr√≥ el archivo CSV\")\n",
    "    print(f\"üìç Buscando en: {CSV_PATH}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error al cargar datos: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4c78bb",
   "metadata": {},
   "source": [
    "## 3. Carga de Datos de Estudiantes\n",
    "\n",
    "Cargamos el archivo CSV que contiene la informaci√≥n de los estudiantes, incluyendo las columnas `Sonar_Ap1` y `Sonar_Ap2` que contienen las claves de los proyectos en SonarCloud.\n",
    "\n",
    "### Estructura esperada del CSV:\n",
    "- **ID**: Identificador √∫nico del estudiante\n",
    "- **Nombre**: Nombre del estudiante  \n",
    "- **Sonar_Ap1**: Clave del proyecto de la Aplicaci√≥n 1 en SonarCloud\n",
    "- **Sonar_Ap2**: Clave del proyecto de la Aplicaci√≥n 2 en SonarCloud\n",
    "- **Otras columnas**: Informaci√≥n adicional del estudiante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49c7d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer project keys de SonarCloud\n",
    "def extract_project_keys(df):\n",
    "    \"\"\"\n",
    "    Extraer todas las claves de proyecto de SonarCloud del DataFrame\n",
    "    \"\"\"\n",
    "    project_keys = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        student_id = row.get('ID', f'Student_{index}')\n",
    "        nombre = row.get('Nombre', 'Unknown')\n",
    "        \n",
    "        # Procesar Sonar_Ap1\n",
    "        if pd.notna(row['Sonar_Ap1']) and row['Sonar_Ap1'].strip():\n",
    "            project_keys.append({\n",
    "                'student_id': student_id,\n",
    "                'nombre': nombre,\n",
    "                'project_key': row['Sonar_Ap1'].strip(),\n",
    "                'assignment': 'AP1',\n",
    "                'row_index': index\n",
    "            })\n",
    "        \n",
    "        # Procesar Sonar_Ap2\n",
    "        if pd.notna(row['Sonar_Ap2']) and row['Sonar_Ap2'].strip():\n",
    "            project_keys.append({\n",
    "                'student_id': student_id,\n",
    "                'nombre': nombre,\n",
    "                'project_key': row['Sonar_Ap2'].strip(),\n",
    "                'assignment': 'AP2',\n",
    "                'row_index': index\n",
    "            })\n",
    "    \n",
    "    return project_keys\n",
    "\n",
    "# Extraer project keys\n",
    "project_list = extract_project_keys(df_estudiantes)\n",
    "\n",
    "print(f\"üîë Total de project keys extra√≠dos: {len(project_list)}\")\n",
    "\n",
    "# Mostrar estad√≠sticas por assignment\n",
    "ap1_count = len([p for p in project_list if p['assignment'] == 'AP1'])\n",
    "ap2_count = len([p for p in project_list if p['assignment'] == 'AP2'])\n",
    "\n",
    "print(f\"üìä Proyectos AP1: {ap1_count}\")\n",
    "print(f\"üìä Proyectos AP2: {ap2_count}\")\n",
    "\n",
    "# Mostrar algunos ejemplos\n",
    "print(\"\\nüîç Primeros 5 project keys:\")\n",
    "for i, project in enumerate(project_list[:5]):\n",
    "    print(f\"  {i+1}. {project['nombre']} - {project['assignment']}: {project['project_key']}\")\n",
    "\n",
    "# Crear DataFrame con los project keys\n",
    "df_projects = pd.DataFrame(project_list)\n",
    "print(f\"\\n‚úÖ DataFrame de proyectos creado con {len(df_projects)} filas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c8981b",
   "metadata": {},
   "source": [
    "## 4. Extracci√≥n de Claves de Proyecto\n",
    "\n",
    "Procesamos el DataFrame de estudiantes para extraer todas las claves de proyecto de SonarCloud disponibles. Cada estudiante puede tener hasta 2 proyectos (AP1 y AP2).\n",
    "\n",
    "### Proceso de extracci√≥n:\n",
    "1. **Iteraci√≥n por estudiante**: Revisamos cada fila del DataFrame\n",
    "2. **Validaci√≥n de datos**: Verificamos que las celdas no est√©n vac√≠as\n",
    "3. **Estructuraci√≥n**: Creamos una lista con la informaci√≥n del proyecto y estudiante\n",
    "4. **Categorizaci√≥n**: Separamos por assignment (AP1 vs AP2)\n",
    "\n",
    "El resultado es una lista estructurada que facilita el procesamiento posterior con la API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aed2ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones para interactuar con SonarCloud API\n",
    "def fetch_project_metrics(project_key: str, metrics_list: List[str]) -> Dict:\n",
    "    \"\"\"\n",
    "    Obtener m√©tricas de un proyecto espec√≠fico desde SonarCloud\n",
    "    \"\"\"\n",
    "    url = f\"{SONAR_BASE_URL}/measures/component\"\n",
    "    \n",
    "    # Par√°metros para la API\n",
    "    params = {\n",
    "        'component': project_key,\n",
    "        'metricKeys': ','.join(metrics_list)\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Realizar petici√≥n a la API\n",
    "        response = requests.get(url, params=params, headers=get_auth_headers(), timeout=30)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            \n",
    "            # Extraer m√©tricas del response\n",
    "            metrics_dict = {'project_key': project_key, 'status': 'success'}\n",
    "            \n",
    "            if 'component' in data and 'measures' in data['component']:\n",
    "                for measure in data['component']['measures']:\n",
    "                    metric_key = measure['metric']\n",
    "                    metric_value = measure.get('value', None)\n",
    "                    \n",
    "                    # Convertir valores num√©ricos\n",
    "                    if metric_value is not None:\n",
    "                        try:\n",
    "                            # Intentar convertir a float\n",
    "                            if '.' in str(metric_value) or metric_key in ['coverage', 'duplicated_lines_density', 'comment_lines_density']:\n",
    "                                metrics_dict[metric_key] = float(metric_value)\n",
    "                            else:\n",
    "                                metrics_dict[metric_key] = int(metric_value)\n",
    "                        except ValueError:\n",
    "                            # Mantener como string si no se puede convertir\n",
    "                            metrics_dict[metric_key] = metric_value\n",
    "                    else:\n",
    "                        metrics_dict[metric_key] = None\n",
    "            \n",
    "            # Agregar m√©tricas faltantes como None\n",
    "            for metric in metrics_list:\n",
    "                if metric not in metrics_dict:\n",
    "                    metrics_dict[metric] = None\n",
    "                    \n",
    "            return metrics_dict\n",
    "            \n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  Error {response.status_code} para proyecto {project_key}\")\n",
    "            return {'project_key': project_key, 'status': 'error', 'error_code': response.status_code}\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"‚ùå Error de conexi√≥n para proyecto {project_key}: {e}\")\n",
    "        return {'project_key': project_key, 'status': 'connection_error', 'error': str(e)}\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error inesperado para proyecto {project_key}: {e}\")\n",
    "        return {'project_key': project_key, 'status': 'unexpected_error', 'error': str(e)}\n",
    "\n",
    "def batch_fetch_metrics(project_list: List[Dict], batch_size: int = 5, delay: float = 1.0) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Obtener m√©tricas para m√∫ltiples proyectos con control de rate limiting\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    total_projects = len(project_list)\n",
    "    \n",
    "    print(f\"üöÄ Iniciando extracci√≥n de m√©tricas para {total_projects} proyectos\")\n",
    "    print(f\"‚öôÔ∏è  Batch size: {batch_size}, Delay: {delay}s\")\n",
    "    \n",
    "    for i in range(0, total_projects, batch_size):\n",
    "        batch = project_list[i:i + batch_size]\n",
    "        batch_num = (i // batch_size) + 1\n",
    "        total_batches = (total_projects + batch_size - 1) // batch_size\n",
    "        \n",
    "        print(f\"\\nüì¶ Procesando batch {batch_num}/{total_batches} ({len(batch)} proyectos)\")\n",
    "        \n",
    "        for project in batch:\n",
    "            project_key = project['project_key']\n",
    "            print(f\"  üîÑ Extrayendo m√©tricas de: {project_key}\")\n",
    "            \n",
    "            # Obtener m√©tricas\n",
    "            metrics = fetch_project_metrics(project_key, METRICS)\n",
    "            \n",
    "            # Combinar informaci√≥n del proyecto con las m√©tricas\n",
    "            result = {**project, **metrics}\n",
    "            results.append(result)\n",
    "            \n",
    "            # Status indicator\n",
    "            if metrics['status'] == 'success':\n",
    "                print(f\"    ‚úÖ √âxito\")\n",
    "            else:\n",
    "                print(f\"    ‚ùå Error: {metrics.get('status', 'unknown')}\")\n",
    "        \n",
    "        # Delay entre batches para evitar rate limiting\n",
    "        if i + batch_size < total_projects:\n",
    "            print(f\"  ‚è≥ Esperando {delay}s antes del siguiente batch...\")\n",
    "            time.sleep(delay)\n",
    "    \n",
    "    print(f\"\\nüéâ Extracci√≥n completada: {len(results)} proyectos procesados\")\n",
    "    return results\n",
    "\n",
    "print(\"üõ†Ô∏è  Funciones de API configuradas\")\n",
    "print(\"üì° Listo para extraer m√©tricas de SonarCloud\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1929459c",
   "metadata": {},
   "source": [
    "## 5. Funciones de Interacci√≥n con la API\n",
    "\n",
    "Definimos las funciones principales para interactuar con la API de SonarCloud de manera eficiente y robusta.\n",
    "\n",
    "### Funciones implementadas:\n",
    "\n",
    "#### `fetch_project_metrics(project_key, metrics_list)`\n",
    "- **Prop√≥sito**: Obtener m√©tricas de un proyecto espec√≠fico\n",
    "- **Endpoint**: `/api/measures/component`\n",
    "- **Manejo de errores**: Captura errores de conexi√≥n, timeouts y respuestas inv√°lidas\n",
    "- **Conversi√≥n de tipos**: Convierte autom√°ticamente valores num√©ricos\n",
    "\n",
    "#### `batch_fetch_metrics(project_list, batch_size, delay)`\n",
    "- **Prop√≥sito**: Procesar m√∫ltiples proyectos con control de rate limiting\n",
    "- **Rate limiting**: Implementa delays entre batches para evitar sobrecargar la API\n",
    "- **Monitoreo**: Proporciona feedback en tiempo real del progreso\n",
    "- **Tolerancia a fallos**: Contin√∫a procesando aunque fallen proyectos individuales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1640db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar extracci√≥n de m√©tricas\n",
    "print(\"üöÄ Iniciando proceso de extracci√≥n de m√©tricas...\")\n",
    "print(f\"üìä Total de proyectos a procesar: {len(project_list)}\")\n",
    "\n",
    "# Configurar par√°metros de extracci√≥n\n",
    "BATCH_SIZE = 3  # Reducir para evitar rate limiting\n",
    "DELAY_BETWEEN_BATCHES = 2.0  # Segundos de espera entre batches\n",
    "\n",
    "# Ejecutar extracci√≥n\n",
    "metrics_results = batch_fetch_metrics(\n",
    "    project_list=project_list,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    delay=DELAY_BETWEEN_BATCHES\n",
    ")\n",
    "\n",
    "print(\"\\nüìà Resultados de la extracci√≥n:\")\n",
    "print(f\"‚úÖ Total de proyectos procesados: {len(metrics_results)}\")\n",
    "\n",
    "# Analizar resultados\n",
    "successful_extractions = [r for r in metrics_results if r.get('status') == 'success']\n",
    "failed_extractions = [r for r in metrics_results if r.get('status') != 'success']\n",
    "\n",
    "print(f\"‚úÖ Extracciones exitosas: {len(successful_extractions)}\")\n",
    "print(f\"‚ùå Extracciones fallidas: {len(failed_extractions)}\")\n",
    "\n",
    "if failed_extractions:\n",
    "    print(\"\\n‚ö†Ô∏è  Proyectos con errores:\")\n",
    "    for failed in failed_extractions[:5]:  # Mostrar solo los primeros 5\n",
    "        print(f\"  - {failed['project_key']}: {failed.get('status', 'unknown error')}\")\n",
    "\n",
    "# Mostrar ejemplo de m√©tricas extra√≠das\n",
    "if successful_extractions:\n",
    "    print(\"\\nüîç Ejemplo de m√©tricas extra√≠das (primer proyecto exitoso):\")\n",
    "    example = successful_extractions[0]\n",
    "    print(f\"Proyecto: {example['project_key']}\")\n",
    "    print(f\"Estudiante: {example['nombre']}\")\n",
    "    print(f\"Assignment: {example['assignment']}\")\n",
    "    \n",
    "    # Mostrar algunas m√©tricas clave\n",
    "    key_metrics = ['bugs', 'vulnerabilities', 'code_smells', 'ncloc', 'coverage']\n",
    "    for metric in key_metrics:\n",
    "        value = example.get(metric, 'N/A')\n",
    "        print(f\"  {metric}: {value}\")\n",
    "        \n",
    "print(\"\\n‚úÖ Extracci√≥n de m√©tricas completada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b94225d",
   "metadata": {},
   "source": [
    "## 6. Ejecuci√≥n de la Extracci√≥n de M√©tricas\n",
    "\n",
    "Ejecutamos el proceso principal de extracci√≥n de m√©tricas. Esta es la parte m√°s cr√≠tica del notebook donde se realiza la comunicaci√≥n con SonarCloud.\n",
    "\n",
    "### Par√°metros de configuraci√≥n:\n",
    "- **BATCH_SIZE**: N√∫mero de proyectos a procesar por lote (3 proyectos)\n",
    "- **DELAY_BETWEEN_BATCHES**: Tiempo de espera entre lotes (2 segundos)\n",
    "\n",
    "### Monitoreo del proceso:\n",
    "- ‚úÖ **Extracciones exitosas**: Proyectos procesados correctamente\n",
    "- ‚ùå **Extracciones fallidas**: Proyectos con errores (ej: proyecto no encontrado, permisos)\n",
    "- üìä **Progreso en tiempo real**: Indicadores de estado por cada proyecto\n",
    "\n",
    "> **Nota**: El proceso puede tomar varios minutos dependiendo del n√∫mero de proyectos. Los delays son necesarios para respetar los l√≠mites de la API de SonarCloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d248ca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesar y estructurar los datos extra√≠dos\n",
    "print(\"üîÑ Procesando datos extra√≠dos...\")\n",
    "\n",
    "# Crear DataFrame con las m√©tricas extra√≠das\n",
    "df_metrics = pd.DataFrame(successful_extractions)\n",
    "\n",
    "if len(df_metrics) > 0:\n",
    "    print(f\"üìä DataFrame de m√©tricas creado con {len(df_metrics)} filas\")\n",
    "    \n",
    "    # Mostrar informaci√≥n del DataFrame\n",
    "    print(f\"üìã Columnas disponibles: {len(df_metrics.columns)}\")\n",
    "    \n",
    "    # Separar columnas de informaci√≥n del proyecto vs m√©tricas\n",
    "    info_columns = ['student_id', 'nombre', 'project_key', 'assignment', 'row_index', 'status']\n",
    "    metric_columns = [col for col in df_metrics.columns if col not in info_columns]\n",
    "    \n",
    "    print(f\"üìà M√©tricas extra√≠das: {len(metric_columns)}\")\n",
    "    print(f\"‚ÑπÔ∏è  Columnas de informaci√≥n: {len(info_columns)}\")\n",
    "    \n",
    "    # Mostrar estad√≠sticas b√°sicas de las m√©tricas num√©ricas\n",
    "    numeric_metrics = df_metrics[metric_columns].select_dtypes(include=['number'])\n",
    "    \n",
    "    if len(numeric_metrics.columns) > 0:\n",
    "        print(f\"\\nüìä Estad√≠sticas descriptivas de m√©tricas num√©ricas:\")\n",
    "        print(f\"M√©tricas num√©ricas encontradas: {list(numeric_metrics.columns)}\")\n",
    "        \n",
    "        # Mostrar estad√≠sticas b√°sicas\n",
    "        stats = numeric_metrics.describe()\n",
    "        display(stats.round(2))\n",
    "        \n",
    "        # Verificar valores nulos\n",
    "        null_counts = df_metrics[metric_columns].isnull().sum()\n",
    "        print(f\"\\n‚ùì Valores nulos por m√©trica:\")\n",
    "        for metric, null_count in null_counts.items():\n",
    "            if null_count > 0:\n",
    "                print(f\"  {metric}: {null_count}/{len(df_metrics)} ({null_count/len(df_metrics)*100:.1f}%)\")\n",
    "    \n",
    "    # Mostrar distribuci√≥n por assignment\n",
    "    assignment_dist = df_metrics['assignment'].value_counts()\n",
    "    print(f\"\\nüìä Distribuci√≥n por assignment:\")\n",
    "    for assignment, count in assignment_dist.items():\n",
    "        print(f\"  {assignment}: {count} proyectos\")\n",
    "    \n",
    "    # Mostrar primeras filas del DataFrame\n",
    "    print(f\"\\nüîç Primeras 3 filas del dataset de m√©tricas:\")\n",
    "    display(df_metrics[info_columns + metric_columns[:5]].head(3))\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No se pudieron procesar las m√©tricas extra√≠das\")\n",
    "    df_metrics = pd.DataFrame()\n",
    "\n",
    "print(\"‚úÖ Procesamiento de datos completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab13b5a",
   "metadata": {},
   "source": [
    "## 7. Procesamiento y An√°lisis de Datos Extra√≠dos\n",
    "\n",
    "Convertimos los resultados de la extracci√≥n en un DataFrame estructurado y realizamos un an√°lisis inicial de la calidad de los datos.\n",
    "\n",
    "### An√°lisis incluido:\n",
    "- **üìä Estad√≠sticas descriptivas**: Media, mediana, min, max para m√©tricas num√©ricas\n",
    "- **‚ùì An√°lisis de valores nulos**: Identificaci√≥n de m√©tricas faltantes\n",
    "- **üìà Distribuci√≥n por assignment**: Conteo de proyectos AP1 vs AP2\n",
    "- **üîç Vista previa**: Primeras filas del dataset para validaci√≥n\n",
    "\n",
    "### Separaci√≥n de columnas:\n",
    "- **Informaci√≥n del proyecto**: student_id, nombre, project_key, assignment\n",
    "- **M√©tricas de calidad**: bugs, vulnerabilities, code_smells, etc.\n",
    "\n",
    "Este an√°lisis nos permite identificar patrones y posibles problemas en los datos antes de continuar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88eb02da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar datos de estudiantes con m√©tricas extra√≠das\n",
    "def merge_student_data_with_metrics(df_estudiantes, df_metrics):\n",
    "    \"\"\"\n",
    "    Combinar datos originales de estudiantes con las m√©tricas extra√≠das\n",
    "    \"\"\"\n",
    "    print(\"üîó Iniciando proceso de combinaci√≥n de datos...\")\n",
    "    \n",
    "    # Crear copias para no modificar los originales\n",
    "    df_students_copy = df_estudiantes.copy()\n",
    "    df_metrics_copy = df_metrics.copy()\n",
    "    \n",
    "    # Agregar sufijos a las m√©tricas seg√∫n el assignment\n",
    "    merged_data = []\n",
    "    \n",
    "    for _, student_row in df_students_copy.iterrows():\n",
    "        student_data = student_row.to_dict()\n",
    "        \n",
    "        # Buscar m√©tricas para AP1\n",
    "        ap1_metrics = df_metrics_copy[\n",
    "            (df_metrics_copy['row_index'] == student_row.name) & \n",
    "            (df_metrics_copy['assignment'] == 'AP1')\n",
    "        ]\n",
    "        \n",
    "        if len(ap1_metrics) > 0:\n",
    "            ap1_row = ap1_metrics.iloc[0]\n",
    "            for metric in METRICS:\n",
    "                student_data[f'{metric}_AP1'] = ap1_row.get(metric, None)\n",
    "        else:\n",
    "            # Agregar valores nulos si no hay m√©tricas AP1\n",
    "            for metric in METRICS:\n",
    "                student_data[f'{metric}_AP1'] = None\n",
    "        \n",
    "        # Buscar m√©tricas para AP2\n",
    "        ap2_metrics = df_metrics_copy[\n",
    "            (df_metrics_copy['row_index'] == student_row.name) & \n",
    "            (df_metrics_copy['assignment'] == 'AP2')\n",
    "        ]\n",
    "        \n",
    "        if len(ap2_metrics) > 0:\n",
    "            ap2_row = ap2_metrics.iloc[0]\n",
    "            for metric in METRICS:\n",
    "                student_data[f'{metric}_AP2'] = ap2_row.get(metric, None)\n",
    "        else:\n",
    "            # Agregar valores nulos si no hay m√©tricas AP2\n",
    "            for metric in METRICS:\n",
    "                student_data[f'{metric}_AP2'] = None\n",
    "        \n",
    "        merged_data.append(student_data)\n",
    "    \n",
    "    return pd.DataFrame(merged_data)\n",
    "\n",
    "# Ejecutar combinaci√≥n de datos\n",
    "if len(df_metrics) > 0:\n",
    "    df_combined = merge_student_data_with_metrics(df_estudiantes, df_metrics)\n",
    "    \n",
    "    print(f\"‚úÖ Datos combinados exitosamente\")\n",
    "    print(f\"üë• Estudiantes en dataset combinado: {len(df_combined)}\")\n",
    "    print(f\"üìä Total de columnas: {len(df_combined.columns)}\")\n",
    "    \n",
    "    # Contar columnas de m√©tricas a√±adidas\n",
    "    metric_ap1_cols = [col for col in df_combined.columns if col.endswith('_AP1')]\n",
    "    metric_ap2_cols = [col for col in df_combined.columns if col.endswith('_AP2')]\n",
    "    \n",
    "    print(f\"üìà Columnas de m√©tricas AP1: {len(metric_ap1_cols)}\")\n",
    "    print(f\"üìà Columnas de m√©tricas AP2: {len(metric_ap2_cols)}\")\n",
    "    \n",
    "    # Verificar cobertura de datos\n",
    "    ap1_projects_with_metrics = df_combined[metric_ap1_cols].notna().any(axis=1).sum()\n",
    "    ap2_projects_with_metrics = df_combined[metric_ap2_cols].notna().any(axis=1).sum()\n",
    "    \n",
    "    print(f\"\\nüìä Cobertura de m√©tricas:\")\n",
    "    print(f\"  Estudiantes con m√©tricas AP1: {ap1_projects_with_metrics}\")\n",
    "    print(f\"  Estudiantes con m√©tricas AP2: {ap2_projects_with_metrics}\")\n",
    "    \n",
    "    # Mostrar algunas columnas del dataset combinado\n",
    "    sample_columns = ['Nombre', 'Sonar_Ap1', 'Sonar_Ap2', 'bugs_AP1', 'bugs_AP2', 'ncloc_AP1', 'ncloc_AP2']\n",
    "    available_sample_cols = [col for col in sample_columns if col in df_combined.columns]\n",
    "    \n",
    "    if available_sample_cols:\n",
    "        print(f\"\\nüîç Vista previa del dataset combinado:\")\n",
    "        display(df_combined[available_sample_cols].head(3))\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No se pueden combinar datos sin m√©tricas extra√≠das\")\n",
    "    df_combined = df_estudiantes.copy()\n",
    "\n",
    "print(\"‚úÖ Combinaci√≥n de datos completada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e88b3c",
   "metadata": {},
   "source": [
    "## 8. Combinaci√≥n de Datos de Estudiantes con M√©tricas\n",
    "\n",
    "Integramos las m√©tricas extra√≠das con la informaci√≥n original de los estudiantes para crear un dataset completo y an√°lisis-ready.\n",
    "\n",
    "### Proceso de combinaci√≥n:\n",
    "1. **Mantenimiento de estructura original**: Preservamos todas las columnas del CSV original\n",
    "2. **Adici√≥n de m√©tricas por assignment**: Cada m√©trica se agrega con sufijos `_AP1` y `_AP2`\n",
    "3. **Manejo de datos faltantes**: Asignamos `None` cuando no hay m√©tricas disponibles\n",
    "4. **Validaci√≥n de cobertura**: Calculamos estad√≠sticas de completitud de datos\n",
    "\n",
    "### Estructura del dataset final:\n",
    "- **Columnas originales**: ID, Nombre, Sonar_Ap1, Sonar_Ap2, etc.\n",
    "- **M√©tricas AP1**: bugs_AP1, vulnerabilities_AP1, ncloc_AP1, etc.\n",
    "- **M√©tricas AP2**: bugs_AP2, vulnerabilities_AP2, ncloc_AP2, etc.\n",
    "\n",
    "### Ejemplo de nuevas columnas a√±adidas:\n",
    "```\n",
    "bugs_AP1, bugs_AP2\n",
    "vulnerabilities_AP1, vulnerabilities_AP2  \n",
    "code_smells_AP1, code_smells_AP2\n",
    "ncloc_AP1, ncloc_AP2\n",
    "coverage_AP1, coverage_AP2\n",
    "... (total: 30 nuevas columnas)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d2a12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar resultados y generar reportes\n",
    "from datetime import datetime\n",
    "\n",
    "# Crear timestamp para los archivos\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "print(\"üíæ Preparando exportaci√≥n de resultados...\")\n",
    "\n",
    "# 1. Exportar dataset combinado completo\n",
    "output_file_combined = f\"estudiantes_con_metricas_sonarcloud_{timestamp}.csv\"\n",
    "\n",
    "try:\n",
    "    df_combined.to_csv(output_file_combined, index=False, encoding='utf-8')\n",
    "    print(f\"‚úÖ Dataset combinado exportado: {output_file_combined}\")\n",
    "    print(f\"üìä Filas exportadas: {len(df_combined)}\")\n",
    "    print(f\"üìã Columnas exportadas: {len(df_combined.columns)}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error al exportar dataset combinado: {e}\")\n",
    "\n",
    "# 2. Exportar solo las m√©tricas extra√≠das\n",
    "if len(df_metrics) > 0:\n",
    "    output_file_metrics = f\"metricas_sonarcloud_raw_{timestamp}.csv\"\n",
    "    try:\n",
    "        df_metrics.to_csv(output_file_metrics, index=False, encoding='utf-8')\n",
    "        print(f\"‚úÖ M√©tricas raw exportadas: {output_file_metrics}\")\n",
    "        print(f\"üìä Proyectos exportados: {len(df_metrics)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al exportar m√©tricas raw: {e}\")\n",
    "\n",
    "# 3. Generar reporte de resumen\n",
    "print(f\"\\nüìã REPORTE DE EXTRACCI√ìN DE M√âTRICAS\")\n",
    "print(f\"=\" * 50)\n",
    "print(f\"üïê Fecha y hora: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"üë• Total de estudiantes: {len(df_estudiantes)}\")\n",
    "print(f\"üéØ Proyectos identificados: {len(project_list)}\")\n",
    "print(f\"‚úÖ M√©tricas extra√≠das exitosamente: {len(successful_extractions)}\")\n",
    "print(f\"‚ùå Extracciones fallidas: {len(failed_extractions)}\")\n",
    "print(f\"üìä M√©tricas por proyecto: {len(METRICS)}\")\n",
    "\n",
    "if len(df_combined) > 0:\n",
    "    print(f\"\\nüìà ESTAD√çSTICAS DEL DATASET FINAL:\")\n",
    "    \n",
    "    # Contar estudiantes con datos completos\n",
    "    students_with_ap1 = (df_combined[[col for col in df_combined.columns if col.endswith('_AP1')]].notna().any(axis=1)).sum()\n",
    "    students_with_ap2 = (df_combined[[col for col in df_combined.columns if col.endswith('_AP2')]].notna().any(axis=1)).sum()\n",
    "    students_with_both = (\n",
    "        (df_combined[[col for col in df_combined.columns if col.endswith('_AP1')]].notna().any(axis=1)) &\n",
    "        (df_combined[[col for col in df_combined.columns if col.endswith('_AP2')]].notna().any(axis=1))\n",
    "    ).sum()\n",
    "    \n",
    "    print(f\"  üìä Estudiantes con m√©tricas AP1: {students_with_ap1}\")\n",
    "    print(f\"  üìä Estudiantes con m√©tricas AP2: {students_with_ap2}\")\n",
    "    print(f\"  üìä Estudiantes con ambas m√©tricas: {students_with_both}\")\n",
    "    \n",
    "    # Mostrar cobertura por m√©trica\n",
    "    print(f\"\\nüìä COBERTURA POR M√âTRICA (% de proyectos con datos):\")\n",
    "    for metric in METRICS[:5]:  # Mostrar las primeras 5 m√©tricas\n",
    "        ap1_coverage = df_combined[f'{metric}_AP1'].notna().sum() / len(df_combined) * 100\n",
    "        ap2_coverage = df_combined[f'{metric}_AP2'].notna().sum() / len(df_combined) * 100\n",
    "        print(f\"  {metric}: AP1={ap1_coverage:.1f}%, AP2={ap2_coverage:.1f}%\")\n",
    "\n",
    "# 4. Guardar configuraci√≥n utilizada\n",
    "config_info = {\n",
    "    'timestamp': timestamp,\n",
    "    'total_students': len(df_estudiantes),\n",
    "    'projects_found': len(project_list),\n",
    "    'metrics_extracted': len(successful_extractions),\n",
    "    'extraction_failures': len(failed_extractions),\n",
    "    'metrics_configured': METRICS,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'delay_between_batches': DELAY_BETWEEN_BATCHES\n",
    "}\n",
    "\n",
    "config_file = f\"extraction_config_{timestamp}.json\"\n",
    "try:\n",
    "    with open(config_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(config_info, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"\\n‚úÖ Configuraci√≥n guardada: {config_file}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error al guardar configuraci√≥n: {e}\")\n",
    "\n",
    "print(f\"\\nüéâ EXTRACCI√ìN COMPLETADA EXITOSAMENTE!\")\n",
    "print(f\"üìÅ Archivos generados disponibles en el directorio de trabajo\")\n",
    "print(f\"üìä Listo para an√°lisis posterior de m√©tricas de calidad de software\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a1b64f",
   "metadata": {},
   "source": [
    "## 9. Exportaci√≥n de Resultados y Generaci√≥n de Reportes\n",
    "\n",
    "Finalizamos el proceso exportando los datos procesados y generando reportes comprensivos del proceso de extracci√≥n.\n",
    "\n",
    "### Archivos generados:\n",
    "\n",
    "#### 1. Dataset Combinado\n",
    "- **Archivo**: `estudiantes_con_metricas_sonarcloud_{timestamp}.csv`\n",
    "- **Contenido**: Datos originales de estudiantes + 30 columnas de m√©tricas\n",
    "- **Uso**: An√°lisis estad√≠stico, visualizaciones, machine learning\n",
    "\n",
    "#### 2. M√©tricas Raw\n",
    "- **Archivo**: `metricas_sonarcloud_raw_{timestamp}.csv`\n",
    "- **Contenido**: M√©tricas extra√≠das en formato largo (una fila por proyecto)\n",
    "- **Uso**: An√°lisis detallado por proyecto, debugging\n",
    "\n",
    "#### 3. Configuraci√≥n de Extracci√≥n\n",
    "- **Archivo**: `extraction_config_{timestamp}.json`\n",
    "- **Contenido**: Par√°metros utilizados, m√©tricas configuradas, estad√≠sticas\n",
    "- **Uso**: Reproducibilidad, documentaci√≥n del proceso\n",
    "\n",
    "### Reporte de extracci√≥n:\n",
    "- **üìä Estad√≠sticas generales**: Total de estudiantes, proyectos procesados\n",
    "- **‚úÖ Tasa de √©xito**: Extracciones exitosas vs fallidas\n",
    "- **üìà Cobertura de datos**: Porcentaje de estudiantes con m√©tricas completas\n",
    "- **üìã M√©tricas por categor√≠a**: Distribuci√≥n de completitud por m√©trica\n",
    "\n",
    "> **Importante**: Todos los archivos incluyen un timestamp para evitar sobrescribir resultados anteriores y mantener un historial de extracciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98817515",
   "metadata": {},
   "source": [
    "## ‚úÖ Proceso Completado\n",
    "\n",
    "### Resumen del flujo ejecutado:\n",
    "1. ‚úÖ **Configuraci√≥n**: Librer√≠as y API de SonarCloud configuradas\n",
    "2. ‚úÖ **Carga de datos**: CSV de estudiantes procesado\n",
    "3. ‚úÖ **Extracci√≥n de claves**: Project keys identificados y estructurados\n",
    "4. ‚úÖ **Conexi√≥n API**: Funciones de extracci√≥n implementadas\n",
    "5. ‚úÖ **Extracci√≥n masiva**: M√©tricas obtenidas con rate limiting\n",
    "6. ‚úÖ **Procesamiento**: Datos estructurados y analizados\n",
    "7. ‚úÖ **Combinaci√≥n**: Dataset final con m√©tricas integradas\n",
    "8. ‚úÖ **Exportaci√≥n**: Archivos generados para an√°lisis posterior\n",
    "\n",
    "### Pr√≥ximos pasos sugeridos:\n",
    "- **üìä An√°lisis Exploratorio**: Usar el dataset combinado para an√°lisis estad√≠stico\n",
    "- **üìà Visualizaciones**: Crear gr√°ficos de distribuci√≥n de m√©tricas por assignment\n",
    "- **üîç An√°lisis Comparativo**: Comparar m√©tricas entre AP1 y AP2\n",
    "- **üéØ An√°lisis de Calidad**: Identificar patrones en la calidad del c√≥digo\n",
    "- **üìã Reportes**: Generar reportes de progreso para estudiantes\n",
    "\n",
    "### Archivos disponibles para an√°lisis:\n",
    "Los archivos CSV generados est√°n listos para ser importados en herramientas de an√°lisis como:\n",
    "- **Python**: pandas, matplotlib, seaborn\n",
    "- **R**: ggplot2, dplyr\n",
    "- **Excel/Google Sheets**: Para an√°lisis b√°sico\n",
    "- **Tableau/Power BI**: Para dashboards interactivos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
