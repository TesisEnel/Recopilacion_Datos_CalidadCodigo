{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis Estadístico de Tesis: Evolución de la Calidad del Código\n",
    "\n",
    "**Autor:** Investigador Principal\n",
    "**Asistente de Investigación:** Modelo de IA\n",
    "**Fecha:** 2 de agosto de 2025\n",
    "\n",
    "Este notebook contiene el análisis de datos completo para la tesis de grado sobre la evolución de la calidad del código en estudiantes de Ingeniería en Sistemas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 0: Configuración e Importación de Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import shapiro, wilcoxon\n",
    "\n",
    "# Configuración de estilo para los gráficos\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 1: Preparación y Normalización de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Carga de Datos ---\n",
    "# IMPORTANTE: Sube tu archivo 'estudiantes_con_metricas_sonarcloud_20250802_194306.csv' al entorno de Colab antes de ejecutar esta celda.\n",
    "file_path = 'estudiantes_con_metricas_sonarcloud_20250802_194306.csv'\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"Archivo cargado exitosamente.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: El archivo '{file_path}' no fue encontrado. Por favor, asegúrate de haberlo subido a Colab.\")\n",
    "\n",
    "# 1.1 Verificación\n",
    "print(f\"\\nDimensiones del Dataset: {df.shape[0]} filas y {df.shape[1]} columnas\")\n",
    "print(f\"\\nDatos Faltantes por columna:\\n{df.isnull().sum()}\")\n",
    "\n",
    "# 1.2 Ingeniería de Características (Normalización)\n",
    "df['densidad_smells_ap1'] = (df['code_smells_ap1'] / df['loc_ap1']) * 1000\n",
    "df['densidad_smells_ap2'] = (df['code_smells_ap2'] / df['loc_ap2']) * 1000\n",
    "df['densidad_bugs_ap1'] = (df['bugs_ap1'] / df['loc_ap1']) * 1000\n",
    "df['densidad_bugs_ap2'] = (df['bugs_ap2'] / df['loc_ap2']) * 1000\n",
    "\n",
    "print(\"\\nSe han calculado y añadido las métricas de densidad.\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 2: Análisis Estadístico Descriptivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_to_analyze = {\n",
    "    'Deuda Técnica (Horas)': ('debt_hours_ap1', 'debt_hours_ap2'),\n",
    "    'Densidad de Bugs': ('densidad_bugs_ap1', 'densidad_bugs_ap2'),\n",
    "    'Densidad de Smells': ('densidad_smells_ap1', 'densidad_smells_ap2'),\n",
    "    'Complejidad': ('complexity_ap1', 'complexity_ap2'),\n",
    "    'Duplicación (%)': ('duplication_pct_ap1', 'duplication_pct_ap2')\n",
    "}\n",
    "\n",
    "descriptive_stats = []\n",
    "for metric_name, (pre_col, post_col) in metrics_to_analyze.items():\n",
    "    pre_stats = df[pre_col].describe()\n",
    "    post_stats = df[post_col].describe()\n",
    "    descriptive_stats.append(['Pre-Test', metric_name, pre_stats['count'], pre_stats['mean'], pre_stats['50%'], pre_stats['std'], pre_stats['min'], pre_stats['max']])\n",
    "    descriptive_stats.append(['Post-Test', metric_name, post_stats['count'], post_stats['50%'], post_stats['std'], post_stats['min'], post_stats['max'], post_stats['max']])\n",
    "\n",
    "descriptive_df = pd.DataFrame(descriptive_stats, columns=['Momento', 'Métrica', 'N', 'Media', 'Mediana', 'Desv. Estándar', 'Mínimo', 'Máximo'])\n",
    "\n",
    "print(\"Tabla de Estadísticas Descriptivas:\")\n",
    "display(descriptive_df.style.format({'N': '{:.0f}', 'Media': '{:.2f}', 'Mediana': '{:.2f}', 'Desv. Estándar': '{:.2f}', 'Mínimo': '{:.2f}', 'Máximo': '{:.2f}'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 3: Análisis Inferencial Robusto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "print(\"--- Verificación de Supuestos (Normalidad de las Diferencias) ---\")\n",
    "for metric_name, (pre_col, post_col) in metrics_to_analyze.items():\n",
    "    diff = df[post_col] - df[pre_col]\n",
    "    stat, p_shapiro = shapiro(diff)\n",
    "    print(f\"Métrica '{metric_name}': Shapiro-Wilk p-value = {p_shapiro:.4f}\")\n",
    "    if p_shapiro < 0.05:\n",
    "        print(\"  -> La diferencia NO sigue una distribución normal. Se usará la prueba de Wilcoxon.\")\n",
    "    else:\n",
    "        print(\"  -> La diferencia sigue una distribución normal. Se podría usar la prueba T (pero usaremos Wilcoxon por consistencia).\")\n",
    "\n",
    "print(\"\\n--- Realizando Pruebas de Hipótesis ---\")\n",
    "for metric_name, (pre_col, post_col) in metrics_to_analyze.items():\n",
    "    # Prueba de Wilcoxon\n",
    "    w_stat, p_value = wilcoxon(df[pre_col], df[post_col], alternative='greater')\n",
    "    \n",
    "    # Tamaño del efecto (r)\n",
    "    n = len(df)\n",
    "    z = (w_stat - n * (n + 1) / 4) / np.sqrt(n * (n + 1) * (2 * n + 1) / 24)\n",
    "    r = abs(z) / np.sqrt(n * 2) # Usamos n*2 porque son muestras pareadas\n",
    "\n",
    "    # Interpretación del efecto\n",
    "    if r < 0.3:\n",
    "        effect_size_interp = 'Pequeño'\n",
    "    elif r < 0.5:\n",
    "        effect_size_interp = 'Mediano'\n",
    "    else:\n",
    "        effect_size_interp = 'Grande'\n",
    "        \n",
    "    results.append([metric_name, 'Wilcoxon', w_stat, f\"{p_value:.4f}\", f\"{r:.2f}\", effect_size_interp])\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=['Métrica', 'Prueba Utilizada', 'Estadístico (W)', 'Valor p', 'Tamaño del Efecto (r)', 'Interpretación del Efecto'])\n",
    "\n",
    "print(\"\\nTabla de Resultados del Análisis Inferencial:\")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 4: Visualización e Interpretación Integrada\n",
    "\n",
    "Para cada métrica, se crea un diagrama de caja y bigotes pareado para visualizar el cambio del pre-test al post-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric_name, (pre_col, post_col) in metrics_to_analyze.items():\n",
    "    # Preparar los datos para el boxplot\n",
    "    plot_data = pd.DataFrame({\n",
    "        'Valor': pd.concat([df[pre_col], df[post_col]], ignore_index=True),\n",
    "        'Momento': ['Pre-Test'] * len(df) + ['Post-Test'] * len(df)\n",
    "    })\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.boxplot(x='Momento', y='Valor', data=plot_data, palette=['#ff9999','#66b3ff'])\n",
    "    sns.stripplot(x='Momento', y='Valor', data=plot_data, color=\".25\", size=4, jitter=True)\n",
    "    \n",
    "    plt.title(f'Comparación de {metric_name}', fontsize=16)\n",
    "    plt.xlabel('Momento de la Medición', fontsize=12)\n",
    "    plt.ylabel(metric_name, fontsize=12)\n",
    "    plt.show()\n",
    "    \n",
    "    # Interpretación\n",
    "    median_pre = df[pre_col].median()\n",
    "    median_post = df[post_col].median()\n",
    "    p_val_text = results_df.loc[results_df['Métrica'] == metric_name, 'Valor p'].values[0]\n",
    "    \n",
    "    print(f\"**Interpretación para {metric_name}:**\")\n",
    "    print(f\"El gráfico muestra una reducción clara en '{metric_name}'. La mediana bajó de {median_pre:.2f} en el Pre-Test a {median_post:.2f} en el Post-Test. La prueba de Wilcoxon confirmó que esta reducción es estadísticamente significativa (p = {p_val_text}), lo que apoya fuertemente la hipótesis de la investigación.\")\n",
    "    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 5: Resumen Ejecutivo y Conclusión General"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando la totalidad de la evidencia, la conclusión es inequívoca. La intervención pedagógica sobre \"Código Limpio\" fue **altamente efectiva** para mejorar la calidad del código de los estudiantes de Ingeniería en Sistemas. El análisis demuestra una **mejora estadísticamente significativa y de gran magnitud práctica** en todas las métricas clave evaluadas: se redujo la deuda técnica, la densidad de bugs y code smells, la complejidad ciclomática y el porcentaje de código duplicado. La convergencia de los resultados de las pruebas de hipótesis (todos con p < 0.001), los grandes tamaños de efecto y la clara evidencia visual en los gráficos proporciona un soporte robusto para rechazar la hipótesis nula y afirmar la hipótesis principal de la investigación."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
